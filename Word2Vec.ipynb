{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1g52Ao3GtVXF2Ydc9QvdPtGAUsec11oRi",
      "authorship_tag": "ABX9TyMvC+6qz0PplMkD/oTqOmVP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQhL4EpEEnJ1",
        "colab_type": "code",
        "outputId": "b0496c15-5211-4037-a5a0-ed943bb91a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think they really let the quality of the DVD...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm sorry but this is just awful. I have told ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Japenese sense of pacing, editing and musi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the '60's/'70's, David Jason was renowned f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Hail The Woman\" is one of the most moving fil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  I think they really let the quality of the DVD...      0\n",
              "1  I'm sorry but this is just awful. I have told ...      0\n",
              "2  The Japenese sense of pacing, editing and musi...      0\n",
              "3  In the '60's/'70's, David Jason was renowned f...      1\n",
              "4  \"Hail The Woman\" is one of the most moving fil...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xqlqS_VFg2t",
        "colab_type": "code",
        "outputId": "ee153d5a-c524-45d0-8c7e-e9c71ce28d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "en_stop = list(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if\n",
        "              re.match(r'[^\\W\\d]*$', t) and (len(t) > 2) and (t not in en_stop)]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return tokens\n",
        "\n",
        "tokens = df['review'].apply(tokenize)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2tzA9njJVZl",
        "colab_type": "code",
        "outputId": "f46158e5-b420-4979-bebf-faf65987f099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [think, really, let, quality, dvd, production,...\n",
              "1        [sorry, awful, told, people, film, bad, acting...\n",
              "2        [japenese, sense, pacing, editing, musical, sc...\n",
              "3        [david, jason, renowned, many, supporting, rol...\n",
              "4        [hail, woman, one, moving, film, ever, seen, e...\n",
              "                               ...                        \n",
              "39995    [come, across, gem, movie, like, realize, grea...\n",
              "39996    [often, way, write, comment, warn, anyone, mig...\n",
              "39997    [extremely, silly, little, seen, film, slavery...\n",
              "39998    [saw, movie, scary, thing, people, talking, mo...\n",
              "39999    [though, film, seems, trying, market, horror, ...\n",
              "Name: review, Length: 40000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBGARBl4bufH",
        "colab_type": "text"
      },
      "source": [
        "## **Обучение модели Word2Vec**\n",
        "Корпус текстов IMDB, разбитый на токены, используем для обучения Word2Vec модели. Размерность скрытого предстваления выбрана 64, ширина контекста в каждую сторону равна 3:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn8mf_-n6AvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MSeTfO7i39Z",
        "colab_type": "code",
        "outputId": "2e04b4ac-6ff7-420b-c7ba-e2cdd6f99594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bigrams = Phrases(sentences=tokens)\n",
        "trigrams = Phrases(sentences=bigrams[tokens])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFY_fUV6j8bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = Phraser(bigrams)\n",
        "trigrams = Phraser(trigrams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iGhI2JhQtY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(tokens, size=300, window=6, min_count=4, iter=100, sg=0, sample=1e-5, workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7LuQztOZ-GA",
        "colab_type": "text"
      },
      "source": [
        "## **Векторное представление текста**\n",
        "Мы получили векторные представления для отдельных слов (токенов). Их можно по-разному складывать в векторные представления текста целиком для решения задачи классификации (а можно и не складывать и рассматривать последовательности). В нашем примере берется средний вектор:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOlna3iiTkqh",
        "colab_type": "code",
        "outputId": "b9ce05cb-c1d3-4a16-9c7a-d33853c4d366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def encode(list_of_tokens):\n",
        "    x = np.array([model.wv[t] for t in list_of_tokens if t in model.wv.vocab])\n",
        "\n",
        "    return np.concatenate((np.mean(x, axis=0), np.median(x, axis=0)))\n",
        "\n",
        "fts = np.array([encode(t) for t in tokens])\n",
        "fts.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFbNgONbVsAs",
        "colab_type": "text"
      },
      "source": [
        "Итак, мы получили набор фичей (64 штуки) для каждого текта, можно переходить к моделям классификации!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0vPmOqtVtIO",
        "colab_type": "text"
      },
      "source": [
        "**Разделение датасета**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw1hp5-IUxMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(fts, df.label.values,\n",
        "                                                    test_size=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmiMNAA-VkK-",
        "colab_type": "text"
      },
      "source": [
        "**Модель классификации** <br>\n",
        "\n",
        "Для примера возьмем логистическую регрессию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itHOFRSbU1mH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(solver='lbfgs', max_iter=3000).fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNowKt6OVgs0",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим метрики:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP-BFWDEU3lH",
        "colab_type": "code",
        "outputId": "f439e7f4-5c56-4778-d9d3-a8172da7284c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicts = clf.predict(X_train)\n",
        "print('Train\\n', classification_report(y_train, predicts, digits=4))\n",
        "\n",
        "predicts = clf.predict(X_test)\n",
        "print('Test\\n', classification_report(y_test, predicts, digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8945    0.8921    0.8933     16057\n",
            "           1     0.8917    0.8941    0.8929     15943\n",
            "\n",
            "    accuracy                         0.8931     32000\n",
            "   macro avg     0.8931    0.8931    0.8931     32000\n",
            "weighted avg     0.8931    0.8931    0.8931     32000\n",
            "\n",
            "Test\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8796    0.8820    0.8808      4010\n",
            "           1     0.8811    0.8787    0.8799      3990\n",
            "\n",
            "    accuracy                         0.8804      8000\n",
            "   macro avg     0.8804    0.8804    0.8804      8000\n",
            "weighted avg     0.8804    0.8804    0.8804      8000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k87zFgbjIiQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC().fit(fts, df.label.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQNGzZWNI0A1",
        "colab_type": "code",
        "outputId": "b9884215-095c-4730-d163-2a82ebf97671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicts = clf.predict(X_train)\n",
        "print('Train\\n', classification_report(y_train, predicts, digits=4))\n",
        "\n",
        "predicts = clf.predict(X_test)\n",
        "print('Test\\n', classification_report(y_test, predicts, digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9219    0.9168    0.9194     16048\n",
            "           1     0.9168    0.9219    0.9193     15952\n",
            "\n",
            "    accuracy                         0.9193     32000\n",
            "   macro avg     0.9194    0.9194    0.9193     32000\n",
            "weighted avg     0.9194    0.9193    0.9193     32000\n",
            "\n",
            "Test\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8995    0.8910    0.8952      4019\n",
            "           1     0.8910    0.8995    0.8952      3981\n",
            "\n",
            "    accuracy                         0.8952      8000\n",
            "   macro avg     0.8953    0.8953    0.8952      8000\n",
            "weighted avg     0.8953    0.8952    0.8952      8000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G17rtBdXJg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('test.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdmflkOWVDVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "tok = test['review'].apply(tokenize)\n",
        "mahmax = np.array([encode(t) for t in tok])\n",
        "predicted = clf.predict(mahmax)\n",
        "pd.DataFrame({'Predicted': predicted}).to_csv('/content/drive/My Drive/Colab Notebooks/solution.csv', index_label='Id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DuKuBBgKeHs",
        "colab_type": "code",
        "outputId": "9a971252-6147-4f71-e17e-6f09b44a23d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model_pre = api.load(\"glove-wiki-gigaword-300\")  # load glove vectors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[===========================================-------] 87.7% 329.9/376.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIrmssNxZuD7",
        "colab_type": "code",
        "outputId": "47ba278d-9016-4ae8-eaa4-931f1df44de9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def encode1(list_of_tokens):\n",
        "    x = np.array([model_pre.wv[t] for t in list_of_tokens if t in model_pre.wv.vocab])\n",
        "\n",
        "    return np.concatenate((np.mean(x, axis=0), np.max(x, axis=0), np.median(x, axis=0)))\n",
        "\n",
        "fts_pre = np.array([encode1(t) for t in tokens])\n",
        "fts_pre.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 900)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzxmUJ4iah_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(fts_pre, df.label.values,\n",
        "                                                    test_size=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFFt1o0ha21d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(solver='lbfgs', max_iter=1500).fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVxwboOaa5cF",
        "colab_type": "code",
        "outputId": "1b02b5ea-bb2c-44cf-d53c-ae880438ffa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicts = clf.predict(X_train)\n",
        "print('Train\\n', classification_report(y_train, predicts, digits=4))\n",
        "\n",
        "predicts = clf.predict(X_test)\n",
        "print('Test\\n', classification_report(y_test, predicts, digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8577    0.8500    0.8538     16085\n",
            "           1     0.8498    0.8575    0.8536     15915\n",
            "\n",
            "    accuracy                         0.8537     32000\n",
            "   macro avg     0.8537    0.8537    0.8537     32000\n",
            "weighted avg     0.8538    0.8537    0.8537     32000\n",
            "\n",
            "Test\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8361    0.8478    0.8419      3982\n",
            "           1     0.8470    0.8352    0.8411      4018\n",
            "\n",
            "    accuracy                         0.8415      8000\n",
            "   macro avg     0.8416    0.8415    0.8415      8000\n",
            "weighted avg     0.8416    0.8415    0.8415      8000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6j5eBIja66F",
        "colab_type": "code",
        "outputId": "68bd4c49-0c9c-4132-9efb-480f1b27d6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(list(tokens)[0][:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['think', 'really', 'let', 'quality', 'dvd', 'production', 'get', 'away', 'rented', 'dvd']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}